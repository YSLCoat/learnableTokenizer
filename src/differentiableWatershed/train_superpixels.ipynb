{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import AdamW\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainedVariationLoss(nn.Module):\n",
    "    def __init__(self, num_clusters, eps=1e-8):\n",
    "        super(ExplainedVariationLoss, self).__init__()\n",
    "        self.num_clusters = num_clusters\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, soft_assignments):\n",
    "        \"\"\"\n",
    "        x: (B, C_in, H, W) input image\n",
    "        soft_assignments: (B, C, H, W) soft cluster probabilities\n",
    "        Returns:\n",
    "            loss (scalar): SSR/SST\n",
    "            ev_per_sample (B,): explained variation per sample\n",
    "        \"\"\"\n",
    "        B, C_in, H, W = x.shape\n",
    "\n",
    "        # Compute cluster means\n",
    "        cluster_counts = soft_assignments.sum(dim=(2, 3))  # (B, C)\n",
    "        cluster_sums = (x.unsqueeze(2) * soft_assignments.unsqueeze(1)).sum(dim=(3, 4))  # (B, C_in, C)\n",
    "        cluster_means = cluster_sums / (cluster_counts.unsqueeze(1) + self.eps)  # (B, C_in, C)\n",
    "\n",
    "        # Reconstruct each pixel from cluster means\n",
    "        cluster_means_per_pixel = torch.einsum('bmk,bkhw->bmhw', cluster_means, soft_assignments)\n",
    "\n",
    "        # Compute SST and SSR per sample\n",
    "        # Keep batch dimension by summation over C,H,W only\n",
    "        global_mean = x.mean(dim=(1,2,3), keepdim=True)  # (B,1,1,1)\n",
    "        SST_per_sample = ((x - global_mean)**2).sum(dim=(1,2,3))  # (B,)\n",
    "        SSR_per_sample = ((x - cluster_means_per_pixel)**2).sum(dim=(1,2,3))  # (B,)\n",
    "\n",
    "        # loss = SSR/SST (averaged over batch)\n",
    "        SST_total = SST_per_sample.sum() + self.eps\n",
    "        SSR_total = SSR_per_sample.sum()\n",
    "        loss = SSR_total / SST_total\n",
    "\n",
    "        # Explained variation per sample: 1 - SSR/SST\n",
    "        ev_per_sample = 1.0 - (SSR_per_sample / (SST_per_sample + self.eps))\n",
    "        \n",
    "        return loss, ev_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import segmentation_models_pytorch as smp\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "class DifferentiableVoronoiPropagation(nn.Module):\n",
    "    def __init__(self, num_clusters=196, height=224, width=224, device='cpu', init_std=5.0):\n",
    "        \"\"\"\n",
    "        A differentiable variant of Voronoi propagation.\n",
    "\n",
    "        Changes:\n",
    "        - Centroids are learnable parameters.\n",
    "        - Uses soft-min approximations for cluster assignments.\n",
    "        - Produces a soft assignment map (B, C, H, W) instead of a hard mask.\n",
    "\n",
    "        Args:\n",
    "            num_clusters (int): Number of clusters (centroids).\n",
    "            height (int): Height of the input image.\n",
    "            width (int): Width of the input image.\n",
    "            device (str): 'cpu' or 'cuda'.\n",
    "            init_std (float): Std for centroid initialization around a uniform grid.\n",
    "        \"\"\"\n",
    "        super(DifferentiableVoronoiPropagation, self).__init__()\n",
    "        \n",
    "        self.C = num_clusters\n",
    "        self.H = height\n",
    "        self.W = width\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        # Initialize centroids as learnable parameters\n",
    "        # Start from a grid and add some noise\n",
    "        centroids = self._initialize_centroids()\n",
    "        self.centroids = nn.Parameter(centroids)  # (C, 2) positions [y, x]\n",
    "\n",
    "        self.convert_to_greyscale = torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.num_iters = 20\n",
    "        self.gradient_weight = 10.0\n",
    "        self.color_weight = 10.0\n",
    "        self.edge_exponent = 4.0\n",
    "        self.alpha = 10.0  # controls softness of soft-min\n",
    "\n",
    "    def _initialize_centroids(self):\n",
    "        # Place centroids on a rough grid\n",
    "        num_cols = int(math.sqrt(self.C * self.W / self.H))\n",
    "        num_rows = int(math.ceil(self.C / num_cols))\n",
    "\n",
    "        grid_spacing_y = self.H / num_rows\n",
    "        grid_spacing_x = self.W / num_cols\n",
    "\n",
    "        centroids = []\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "                if len(centroids) >= self.C:\n",
    "                    break\n",
    "                y = (i + 0.5) * grid_spacing_y\n",
    "                x = (j + 0.5) * grid_spacing_x\n",
    "                centroids.append([y, x])\n",
    "            if len(centroids) >= self.C:\n",
    "                break\n",
    "        centroids = torch.tensor(centroids, device=self.device).float()  # (C, 2)\n",
    "        return centroids\n",
    "\n",
    "    def compute_gradient_map(self, x):\n",
    "        # Sobel kernels for single-channel input\n",
    "        sobel_x = torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]], device=x.device, dtype=x.dtype)\n",
    "        sobel_y = torch.tensor([[[[-1, -2, -1],[ 0, 0, 0],[ 1, 2, 1]]]], device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        grad_x = F.conv2d(x, sobel_x, padding=1)\n",
    "        grad_y = F.conv2d(x, sobel_y, padding=1)\n",
    "        \n",
    "        grad_map = torch.sqrt(grad_x.pow(2) + grad_y.pow(2))\n",
    "        return grad_map\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass:\n",
    "        1. Convert to grayscale and compute gradient map.\n",
    "        2. Compute initial cost map based on centroid positions.\n",
    "        3. Iteratively update the cost map using a differentiable approximation.\n",
    "        4. Convert final cost map to soft assignments via a softmax.\n",
    "\n",
    "        Returns:\n",
    "            soft_assignments (Tensor): (B, C, H, W) soft clustering assignments.\n",
    "        \"\"\"\n",
    "        B, C_in, H, W = x.shape\n",
    "        assert H == self.H and W == self.W, \"Input size must match model initialization.\"\n",
    "\n",
    "        if C_in == 3:\n",
    "            grayscale_image = self.convert_to_greyscale(x)\n",
    "        else:\n",
    "            grayscale_image = x\n",
    "\n",
    "        grad_map = self.compute_gradient_map(grayscale_image)\n",
    "\n",
    "        # Initialize distance map for each cluster\n",
    "        # dist_map_per_cluster: (B, C, H, W)\n",
    "        dist_map_per_cluster = torch.full((B, self.C, H, W), float('inf'), device=self.device)\n",
    "\n",
    "        # Place initial centroids: we have continuous centroid positions, but we can assign initial zero cost\n",
    "        # at the pixel closest to each centroid.\n",
    "        cyx = self.centroids  # (C, 2)\n",
    "        int_cy = cyx[:, 0].long().clamp(0, H-1)\n",
    "        int_cx = cyx[:, 1].long().clamp(0, W-1)\n",
    "        for c_idx in range(self.C):\n",
    "            dist_map_per_cluster[:, c_idx, int_cy[c_idx], int_cx[c_idx]] = 0.0\n",
    "\n",
    "        # Weighted gradient map\n",
    "        weighted_grad_map = (grad_map ** self.edge_exponent) * self.gradient_weight  # (B,1,H,W)\n",
    "        \n",
    "        # Directions for propagation (4-connected)\n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "        # Iterative refinement\n",
    "        for _ in range(self.num_iters):\n",
    "            updates = []\n",
    "            for (dy, dx) in directions:\n",
    "                # Shift dist map\n",
    "                shifted_dist = torch.roll(dist_map_per_cluster, shifts=(dy, dx), dims=(2, 3))\n",
    "\n",
    "                # Color difference\n",
    "                shifted_x = torch.roll(x, shifts=(dy, dx), dims=(2,3))\n",
    "                color_diff = torch.abs(x - shifted_x).sum(dim=1, keepdim=True)  # (B,1,H,W)\n",
    "\n",
    "                # Expand color_diff and grad_map along cluster dim\n",
    "                # Weighted cost update for all clusters is:\n",
    "                # old_cost (shifted) + grad_penalty + color_penalty\n",
    "                weighted_dist_update = shifted_dist + weighted_grad_map + color_diff * self.color_weight\n",
    "\n",
    "                # Store updates to combine them differentiably\n",
    "                updates.append(weighted_dist_update)\n",
    "\n",
    "            # Combine all directional updates + current dist_map_per_cluster to get a soft-min over possible updates\n",
    "            # We'll consider the old dist_map_per_cluster as well, so that we never increase cost arbitrarily.\n",
    "            all_candidates = torch.cat([dist_map_per_cluster.unsqueeze(0)] + [u.unsqueeze(0) for u in updates], dim=0)\n",
    "            # all_candidates: (1+len(directions), B, C, H, W)\n",
    "\n",
    "            # Soft-min approximation across the first dimension (candidates)\n",
    "            # Soft-min is implemented as:\n",
    "            # soft_min(x) = -1/alpha * logsumexp(-alpha * x)\n",
    "            # We do this across dimension 0 of all_candidates:\n",
    "            dist_map_per_cluster = -torch.logsumexp(-self.alpha * all_candidates, dim=0) / self.alpha\n",
    "            # This produces a differentiable approximation of taking the minimum over candidates.\n",
    "\n",
    "        # After refinement, we have a differentiable \"cost\" for assigning each pixel to each cluster.\n",
    "        # Convert to soft assignments:\n",
    "        # Higher cost = lower probability, so we do softmax(-dist_map_per_cluster)\n",
    "        soft_assignments = F.softmax(-dist_map_per_cluster, dim=1)  # (B, C, H, W)\n",
    "\n",
    "        return soft_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSDS500Dataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.images_dir = os.path.join(root_dir, 'images', split)\n",
    "        self.ground_truth_dir = os.path.join(root_dir, 'ground_truth', split)\n",
    "        self.image_files = [f for f in os.listdir(self.images_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_name = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        gt_name = os.path.join(self.ground_truth_dir, self.image_files[idx].replace('.jpg', '.mat'))\n",
    "        gt_data = sio.loadmat(gt_name)\n",
    "        ground_truth = gt_data['groundTruth'][0][0][0][0][1]\n",
    "\n",
    "        segmentation = ground_truth\n",
    "        \n",
    "        if isinstance(segmentation, np.ndarray) and segmentation.shape == (1, 1):\n",
    "            segmentation = segmentation[0, 0]\n",
    "        \n",
    "        segmentation = Image.fromarray(segmentation)\n",
    "        segmentation = segmentation.resize((224, 224), Image.NEAREST)\n",
    "        \n",
    "        segmentation = np.array(segmentation, dtype=np.int64)\n",
    "\n",
    "        segmentation = torch.tensor(segmentation, dtype=torch.long)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet mean and std\n",
    "])\n",
    "\n",
    "dataset_train = BSDS500Dataset(root_dir=r'D:\\Data\\BSDS500\\data', split='train', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 196\n",
    "\n",
    "model = DifferentiableVoronoiPropagation(NUM_CLUSTERS, device='cuda').to('cuda')\n",
    "\n",
    "optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-3\n",
    ")\n",
    "\n",
    "loss_fn = ExplainedVariationLoss(NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Batch 1: Loss = 0.1888, EV (batch) = 0.8112\n",
      "Per-sample EV: [0.8112046718597412]\n",
      "Batch 2: Loss = 0.3680, EV (batch) = 0.6320\n",
      "Per-sample EV: [0.6320116519927979]\n",
      "Batch 3: Loss = 0.1375, EV (batch) = 0.8625\n",
      "Per-sample EV: [0.8625314235687256]\n",
      "Batch 4: Loss = 0.0885, EV (batch) = 0.9115\n",
      "Per-sample EV: [0.9114894270896912]\n",
      "Batch 5: Loss = 0.0040, EV (batch) = 0.9960\n",
      "Per-sample EV: [0.9959653615951538]\n",
      "Batch 6: Loss = 0.1591, EV (batch) = 0.8409\n",
      "Per-sample EV: [0.8409422039985657]\n",
      "Batch 7: Loss = 0.2108, EV (batch) = 0.7892\n",
      "Per-sample EV: [0.7891957759857178]\n",
      "Batch 8: Loss = 0.3765, EV (batch) = 0.6235\n",
      "Per-sample EV: [0.6235032081604004]\n",
      "Batch 9: Loss = 0.1898, EV (batch) = 0.8102\n",
      "Per-sample EV: [0.8102400302886963]\n",
      "Batch 10: Loss = 0.2436, EV (batch) = 0.7564\n",
      "Per-sample EV: [0.7563931941986084]\n",
      "Batch 11: Loss = 0.1270, EV (batch) = 0.8730\n",
      "Per-sample EV: [0.8730224370956421]\n",
      "Batch 12: Loss = 0.3345, EV (batch) = 0.6655\n",
      "Per-sample EV: [0.6654926538467407]\n",
      "Batch 13: Loss = 0.0800, EV (batch) = 0.9200\n",
      "Per-sample EV: [0.9199890494346619]\n",
      "Batch 14: Loss = 0.0982, EV (batch) = 0.9018\n",
      "Per-sample EV: [0.9018049240112305]\n",
      "Batch 15: Loss = 0.1090, EV (batch) = 0.8910\n",
      "Per-sample EV: [0.8910088539123535]\n",
      "Batch 16: Loss = 0.2548, EV (batch) = 0.7452\n",
      "Per-sample EV: [0.7451871633529663]\n",
      "Batch 17: Loss = 0.0679, EV (batch) = 0.9321\n",
      "Per-sample EV: [0.9320759177207947]\n",
      "Batch 18: Loss = 0.3005, EV (batch) = 0.6995\n",
      "Per-sample EV: [0.699519157409668]\n",
      "Batch 19: Loss = 0.2135, EV (batch) = 0.7865\n",
      "Per-sample EV: [0.7864921689033508]\n",
      "Batch 20: Loss = 0.1001, EV (batch) = 0.8999\n",
      "Per-sample EV: [0.8998668193817139]\n",
      "Batch 21: Loss = 0.2564, EV (batch) = 0.7436\n",
      "Per-sample EV: [0.7436052560806274]\n",
      "Batch 22: Loss = 0.1407, EV (batch) = 0.8593\n",
      "Per-sample EV: [0.8592993021011353]\n",
      "Batch 23: Loss = 0.2040, EV (batch) = 0.7960\n",
      "Per-sample EV: [0.7960427403450012]\n",
      "Batch 24: Loss = 0.2063, EV (batch) = 0.7937\n",
      "Per-sample EV: [0.7936757802963257]\n",
      "Batch 25: Loss = 0.2473, EV (batch) = 0.7527\n",
      "Per-sample EV: [0.7527112364768982]\n",
      "Batch 26: Loss = 0.1377, EV (batch) = 0.8623\n",
      "Per-sample EV: [0.8622774481773376]\n",
      "Batch 27: Loss = 0.3012, EV (batch) = 0.6988\n",
      "Per-sample EV: [0.6988130211830139]\n",
      "Batch 28: Loss = 0.4377, EV (batch) = 0.5623\n",
      "Per-sample EV: [0.5622984766960144]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Print explained variation per batch and per sample\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m ev_batch_mean \u001b[38;5;241m=\u001b[39m \u001b[43mev_per_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, EV (batch) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mev_batch_mean\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-sample EV:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ev_per_sample\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example hyperparameters\n",
    "max_epochs = 10\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "    for batch_idx, source in enumerate(train_loader):\n",
    "        # Move data to GPU if available\n",
    "        source = source.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: model returns soft assignments (B, C, H, W)\n",
    "        output = model(source)  \n",
    "        \n",
    "        # Compute loss and explained variation\n",
    "        loss, ev_per_sample = loss_fn(source, output)\n",
    "        \n",
    "        loss.requires_grad = True\n",
    "\n",
    "        # Backward pass and parameter update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print explained variation per batch and per sample\n",
    "        ev_batch_mean = ev_per_sample.mean().item()\n",
    "        print(f\"Batch {batch_idx+1}: Loss = {loss.item():.4f}, EV (batch) = {ev_batch_mean:.4f}\")\n",
    "        print(\"Per-sample EV:\", ev_per_sample.tolist())\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
